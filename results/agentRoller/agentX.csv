Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Policy/Epsilon,Policy/Beta,Is Training
50000,1.4145449,15.640599001663894,-0.14354631,0.2699733688415446,0.2699733688415446,0.2469888,0.024367224,0.00028462472,0.1948749,0.0047442573,1.0
100000,1.3957567,10.868264894374555,0.31331256,0.47709470685971994,0.47709470685971994,0.08462792,0.022649333,0.00025696118,0.18565372,0.0042841206,1.0
150000,1.3791314,10.478191000918274,0.55392027,0.6751606978879706,0.6751606978879706,0.06505795,0.027594421,0.00022620882,0.17540292,0.0037726057,1.0
200000,1.3657695,10.16342933690556,0.7994534,0.8814467515070328,0.8814467515070328,0.03275415,0.024637483,0.00019546025,0.16515341,0.003261155,1.0
250000,1.3522696,9.03512645523886,0.9158237,0.9682858289843437,0.9682858289843437,0.014595896,0.02276111,0.00016471805,0.15490602,0.0027498095,1.0
